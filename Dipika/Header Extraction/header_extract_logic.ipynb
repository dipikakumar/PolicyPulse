{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEAd5eW0tGPO",
        "outputId": "d5163639-7c92-4c64-f519-ab8881cae78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/232.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "import re\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8MoOTx-T994",
        "outputId": "b4d8aa45-93cb-42ef-ab46-8b54d9187526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict"
      ],
      "metadata": {
        "id": "HBRMrz1nuVM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the spaCy model\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# def extract_text_from_pdf(file_path: str) -> str:\n",
        "#     \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "#     pdf_file_obj = open(file_path, 'rb')\n",
        "#     pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
        "#     num_pages = len(pdf_reader.pages)\n",
        "#     text = ''\n",
        "#     for page in range(num_pages):\n",
        "#         page_obj = pdf_reader.pages[page]\n",
        "#         text += page_obj.extract_text()\n",
        "#     pdf_file_obj.close()\n",
        "#     return text\n",
        "\n",
        "\n",
        "# def extract_section_headers(text: str) -> List[Dict]:\n",
        "#     \"\"\"Extracts section headers from the given text.\"\"\"\n",
        "#     doc = nlp(text)\n",
        "#     section_headers = []\n",
        "\n",
        "#     # Patterns to identify headers\n",
        "#     common_header_keywords = [\n",
        "#         \"privacy\", \"policy\", \"data\", \"information\", \"rights\", \"contact\", \"changes\",\n",
        "#         \"security\", \"collect\", \"use\", \"share\", \"protect\", \"cookie\", \"terms\", \"personal\"\n",
        "#     ]\n",
        "\n",
        "#     for sent in doc.sents:\n",
        "#         text = sent.text.strip()\n",
        "\n",
        "#         # Skip overly short sentences or purely numeric content\n",
        "#         if len(text) < 5 or text.isdigit():\n",
        "#             continue\n",
        "\n",
        "#         # Check for header-like features\n",
        "#         if (\n",
        "#             text.istitle() or text.isupper() or any(word.lower() in text.lower() for word in common_header_keywords)\n",
        "#         ) and len(text.split()) <= 10:  # Limit to concise headers\n",
        "#             section_headers.append({\"text\": text})\n",
        "\n",
        "#     return section_headers\n",
        "\n",
        "\n",
        "# def process_pdfs_in_directory(directory_path: str) -> Dict:\n",
        "#     \"\"\"Processes PDF files in the given directory.\"\"\"\n",
        "#     pdf_files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]\n",
        "#     results = {}\n",
        "#     for pdf_file in pdf_files:\n",
        "#         file_path = os.path.join(directory_path, pdf_file)\n",
        "#         text = extract_text_from_pdf(file_path)\n",
        "#         section_headers = extract_section_headers(text)\n",
        "#         results[pdf_file] = section_headers\n",
        "#     return results\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# directory_path = \"/content/drive/MyDrive/210 Capstone/policy\"\n",
        "# results = process_pdfs_in_directory(directory_path)\n",
        "\n",
        "# # Save results to Excel\n",
        "# with pd.ExcelWriter(f\"{directory_path}/section_headers_output.xlsx\") as writer:\n",
        "#     for pdf_file, section_headers in results.items():\n",
        "#         df = pd.DataFrame(section_headers)\n",
        "#         sheet_name = pdf_file.split('.')[0][:31]  # Sheet names must be <= 31 chars\n",
        "#         df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "Q3DWlzydryPE",
        "outputId": "4189303e-1b9d-4041-da99-90591b3222c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/path/to/pdf/directory'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5da2ffb9a3cf>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mdirectory_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/path/to/pdf/directory\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_pdfs_in_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Save results to an Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-5da2ffb9a3cf>\u001b[0m in \u001b[0;36mprocess_pdfs_in_directory\u001b[0;34m(directory_path)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_pdfs_in_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;34m\"\"\"Processes all PDFs in a directory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mpdf_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpdf_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/pdf/directory'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import PyPDF2\n",
        "# import spacy\n",
        "# import pandas as pd\n",
        "# import os\n",
        "# import re\n",
        "# from typing import List, Dict\n",
        "\n",
        "# # Load the spaCy model\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# def extract_text_from_pdf(file_path: str) -> str:\n",
        "#     \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "#     with open(file_path, 'rb') as pdf_file_obj:\n",
        "#         pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
        "#         text = ''\n",
        "#         for page in pdf_reader.pages:\n",
        "#             text += page.extract_text()\n",
        "#     return text\n",
        "\n",
        "\n",
        "# def is_potential_header(text: str) -> bool:\n",
        "#     \"\"\"Determine if a given line is likely a section header.\"\"\"\n",
        "#     # Common header keywords\n",
        "#     header_keywords = [\n",
        "#         \"privacy\", \"policy\", \"data\", \"information\", \"rights\", \"contact\", \"security\",\n",
        "#         \"collect\", \"use\", \"share\", \"protect\", \"cookie\", \"terms\", \"personal\"\n",
        "#     ]\n",
        "\n",
        "#     # Basic filtering criteria\n",
        "#     if len(text.split()) > 10:  # Headers should be short\n",
        "#         return False\n",
        "#     if re.match(r\"^[\\d\\s\\W]+$\", text):  # Ignore numeric/symbolic-only lines\n",
        "#         return False\n",
        "#     if \"copyright\" in text.lower() or \"protected by\" in text.lower():  # Ignore legal notices\n",
        "#         return False\n",
        "#     if any(word in text.lower() for word in header_keywords):  # Check for key terms\n",
        "#         return True\n",
        "#     return False\n",
        "\n",
        "\n",
        "# def extract_section_headers(text: str) -> List[Dict]:\n",
        "#     \"\"\"Extracts section headers from the given text.\"\"\"\n",
        "#     doc = nlp(text)\n",
        "#     section_headers = []\n",
        "\n",
        "#     for sent in doc.sents:\n",
        "#         text = sent.text.strip()\n",
        "#         if is_potential_header(text):  # Apply filtering\n",
        "#             section_headers.append({\"text\": text})\n",
        "#     return section_headers\n",
        "\n",
        "\n",
        "# def process_pdf(file_path: str) -> pd.DataFrame:\n",
        "#     \"\"\"Processes a single PDF to extract headers.\"\"\"\n",
        "#     text = extract_text_from_pdf(file_path)\n",
        "#     headers = extract_section_headers(text)\n",
        "#     return pd.DataFrame(headers)\n",
        "\n",
        "\n",
        "# def process_pdfs_in_directory(directory_path: str) -> Dict:\n",
        "#     \"\"\"Processes all PDFs in a directory.\"\"\"\n",
        "#     pdf_files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]\n",
        "#     results = {}\n",
        "#     for pdf_file in pdf_files:\n",
        "#         file_path = os.path.join(directory_path, pdf_file)\n",
        "#         headers_df = process_pdf(file_path)\n",
        "#         results[pdf_file] = headers_df\n",
        "#     return results\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# directory_path = \"/content/drive/MyDrive/210 Capstone/policy/\"\n",
        "# results = process_pdfs_in_directory(directory_path)\n",
        "\n",
        "# # Save results to an Excel file\n",
        "# output_path = \"/content/drive/MyDrive/210 Capstone/section_headers_output.xlsx\"\n",
        "# with pd.ExcelWriter(output_path) as writer:\n",
        "#     for pdf_file, headers_df in results.items():\n",
        "#         sheet_name = pdf_file.split('.')[0][:31]  # Excel sheet name limit\n",
        "#         headers_df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ],
      "metadata": {
        "id": "LR0Cd2BUwVZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load spaCy model\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "# def extract_text_from_pdf(file_path: str) -> str:\n",
        "#     \"\"\"Extracts raw text from a PDF.\"\"\"\n",
        "#     with open(file_path, 'rb') as pdf_file:\n",
        "#         pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "#         text = ''\n",
        "#         for page in pdf_reader.pages:\n",
        "#             text += page.extract_text()\n",
        "#     return text\n",
        "\n",
        "\n",
        "# def is_potential_header(text: str, position_on_page: float = None) -> bool:\n",
        "#     \"\"\"Determine if a line is a valid section header.\"\"\"\n",
        "#     header_keywords = [\n",
        "#         \"privacy\", \"policy\", \"data\", \"information\", \"rights\", \"contact\", \"security\",\n",
        "#         \"collect\", \"use\", \"share\", \"protect\", \"cookie\", \"terms\", \"personal\"\n",
        "#     ]\n",
        "#     if len(text.split()) > 10:  # Too long to be a header\n",
        "#         return False\n",
        "#     if re.match(r\"^[\\d\\s\\W]+$\", text):  # Purely numeric or special characters\n",
        "#         return False\n",
        "#     if \"copyright\" in text.lower() or \"https://\" in text.lower():  # Footers and URLs\n",
        "#         return False\n",
        "#     if position_on_page is not None and position_on_page < 0.1:  # Likely document title\n",
        "#         return False\n",
        "#     return any(word in text.lower() for word in header_keywords)\n",
        "\n",
        "\n",
        "# def extract_section_headers(text: str) -> List[Dict]:\n",
        "#     \"\"\"Extract section headers from text.\"\"\"\n",
        "#     doc = nlp(text)\n",
        "#     headers = []\n",
        "\n",
        "#     for sent in doc.sents:\n",
        "#         text = sent.text.strip()\n",
        "#         # Use basic position-based filtering\n",
        "#         position_on_page = len(text) / len(doc.text)  # Approximation\n",
        "#         if is_potential_header(text, position_on_page=position_on_page):\n",
        "#             headers.append({\"text\": text})\n",
        "#     return headers\n",
        "\n",
        "\n",
        "# def process_pdf(file_path: str) -> pd.DataFrame:\n",
        "#     \"\"\"Process a single PDF to extract section headers.\"\"\"\n",
        "#     text = extract_text_from_pdf(file_path)\n",
        "#     headers = extract_section_headers(text)\n",
        "#     return pd.DataFrame(headers)"
      ],
      "metadata": {
        "id": "_NqlCKXoxVyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import os\n",
        "from typing import List, Dict"
      ],
      "metadata": {
        "id": "uFiasKIp1K2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyHeaderExtractor:\n",
        "    def __init__(self):\n",
        "        self.keywords = [\"privacy\", \"information\", \"data\", \"rights\", \"policy\", \"cookie\", \"contact\", \"security\"]\n",
        "\n",
        "    def extract_document_structure(self, pdf_path: str) -> List[Dict]:\n",
        "        \"\"\"Extract text and layout details.\"\"\"\n",
        "        blocks = []\n",
        "        try:\n",
        "            doc = fitz.open(pdf_path)\n",
        "            for page_num, page in enumerate(doc):\n",
        "                for block in page.get_text(\"dict\")[\"blocks\"]:\n",
        "                    for line in block.get(\"lines\", []):\n",
        "                        for span in line[\"spans\"]:\n",
        "                            text = span[\"text\"].strip()\n",
        "                            if text:\n",
        "                                blocks.append({\n",
        "                                    \"text\": text,\n",
        "                                    \"font_size\": span[\"size\"],\n",
        "                                    \"is_bold\": \"bold\" in span[\"font\"].lower(),\n",
        "                                    \"page_num\": page_num + 1,\n",
        "                                    \"y_position\": line[\"bbox\"][1],\n",
        "                                    \"char_count\": len(text)\n",
        "                                })\n",
        "            return blocks\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {pdf_path}: {e}\")\n",
        "            return []\n",
        "\n",
        "    def identify_headers(self, blocks: List[Dict]) -> pd.DataFrame:\n",
        "        \"\"\"Identify potential headers.\"\"\"\n",
        "        headers = []\n",
        "        for block in blocks:\n",
        "            score = 0\n",
        "            # Prioritize layout features\n",
        "            if block[\"font_size\"] > 12:\n",
        "                score += 1\n",
        "            if block[\"is_bold\"]:\n",
        "                score += 1\n",
        "            if len(block[\"text\"].split()) <= 8:\n",
        "                score += 0.5\n",
        "            if block[\"page_num\"] == 1 and block[\"y_position\"] < 200:\n",
        "                score += 0.5\n",
        "            # Include domain-specific terms\n",
        "            if any(keyword in block[\"text\"].lower() for keyword in self.keywords):\n",
        "                score += 1\n",
        "\n",
        "            if score >= 2:  # Threshold for header inclusion\n",
        "                headers.append({\n",
        "                    \"text\": block[\"text\"],\n",
        "                    \"page_num\": block[\"page_num\"],\n",
        "                    \"font_size\": block[\"font_size\"],\n",
        "                    \"score\": score\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(headers)\n",
        "\n",
        "    def process_policy(self, pdf_path: str) -> pd.DataFrame:\n",
        "        \"\"\"Process a single policy document.\"\"\"\n",
        "        blocks = self.extract_document_structure(pdf_path)\n",
        "        if not blocks:\n",
        "            return pd.DataFrame()\n",
        "        return self.identify_headers(blocks)\n",
        "\n",
        "def process_policies_in_folder(folder_path: str) -> Dict[str, pd.DataFrame]:\n",
        "    \"\"\"Processes all PDF files in a folder.\"\"\"\n",
        "    extractor = PolicyHeaderExtractor()\n",
        "    results = {}\n",
        "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_path = os.path.join(folder_path, pdf_file)\n",
        "        print(f\"Processing {pdf_file}...\")\n",
        "        headers_df = extractor.process_policy(pdf_path)\n",
        "        results[pdf_file] = headers_df\n",
        "    return results\n",
        "\n",
        "# Specify the folder containing the PDFs\n",
        "folder_path = \"/content/drive/MyDrive/210 Capstone/policy/\"\n",
        "\n",
        "# Process all PDFs in the folder\n",
        "results = process_policies_in_folder(folder_path)\n",
        "\n",
        "# Save results to an Excel file\n",
        "output_file = \"/content/drive/MyDrive/210 Capstone/policy_headers_analysis.xlsx\"\n",
        "with pd.ExcelWriter(output_file) as writer:\n",
        "    for pdf, df in results.items():\n",
        "        sheet_name = pdf.split('.')[0][:31]  # Excel sheet name limit\n",
        "        if not df.empty:\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "print(f\"Headers saved to {output_file}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5wNEFBYyKOx",
        "outputId": "c3de4d84-f7af-4fba-a8a2-575dae5dab9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing circle.pdf...\n",
            "Processing revolut.pdf...\n",
            "Processing bitpay.pdf...\n",
            "Processing gemini.pdf...\n",
            "Processing bilt.pdf...\n",
            "Processing moonpay.pdf...\n",
            "Processing 46dc2b81-d389-4a93-3ca0-a530b6db5a6b.pdf...\n",
            "Processing plaid.pdf...\n",
            "Processing klarna.pdf...\n",
            "Processing stripe.pdf...\n",
            "Headers saved to /content/drive/MyDrive/210 Capstone/policy_headers_analysis.xlsx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87R29otI4HLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}